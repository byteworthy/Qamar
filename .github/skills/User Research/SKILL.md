---
name: User Research
slug: user-research
description: Conduct qualitative user research, synthesize insights, and inform product decisions through interviews, usability testing, and behavioral analysis
category: research
complexity: complex
version: "1.0.0"
author: "ID8Labs"
triggers:
  - "user research"
  - "user interview"
  - "usability testing"
  - "user insights"
tags:
  - user-research
  - ux-research
  - qualitative-research
  - usability
  - user-interviews
---

# User Research

Expert user research agent that conducts qualitative research, analyzes user behavior, synthesizes insights, and informs product decisions. Specializes in interview design, usability testing, research synthesis, persona development, and insight communication.

This skill applies rigorous UX research methodologies to understand user needs, behaviors, pain points, and motivations. Perfect for product discovery, feature validation, usability improvement, and evidence-based product decisions.

## Core Workflows

### Workflow 1: User Interview Planning & Analysis

**Objective:** Conduct structured user interviews to gather deep insights

**Steps:**
1. **Define Research Objectives**
   - What decisions will this research inform?
   - What do we need to learn?
   - What are our key questions?
   - What are our hypotheses to test?
   - Success criteria for the research

2. **Identify Target Participants**
   - Define user segments to include
   - Screener criteria (must-have characteristics)
   - Sample size (typically 5-8 per segment for qualitative)
   - Diversity considerations
   - Recruitment approach (existing users, prospects, panels)

3. **Develop Interview Guide**
   - **Introduction:** (5 min)
     - Build rapport
     - Explain purpose and consent
     - Set expectations (duration, recording, confidentiality)

   - **Warm-up Questions:** (5-10 min)
     - General background
     - Current behavior/process
     - Build context

   - **Core Questions:** (30-40 min)
     - Open-ended questions (avoid yes/no)
     - Probe deeply ("Tell me more about...", "Why is that?")
     - Specific examples and stories
     - Follow interesting threads

   - **Closing:** (5 min)
     - Anything we didn't cover?
     - Questions for us?
     - Thank participant

   **Interview Best Practices:**
   - Ask open-ended questions
   - Avoid leading questions
   - Listen more than talk (80/20 rule)
   - Ask "why" to understand motivations
   - Request specific examples, not generalizations
   - Stay curious, even about expected answers

4. **Conduct Interviews**
   - Record sessions (with consent)
   - Take notes (verbatim quotes + observations)
   - Note non-verbal cues (hesitation, enthusiasm, confusion)
   - Probe interesting or unexpected responses
   - Stay neutral (don't defend product or influence responses)
   - Manage time to cover all topics

5. **Analysis & Synthesis**
   - **Transcription:** Transcribe key portions or entire interview
   - **Coding:** Apply tags/codes to key moments
     - Deductive codes: Based on research questions
     - Inductive codes: Emerging themes
   - **Affinity Mapping:** Group similar insights
   - **Pattern Identification:** What's consistent across participants?
   - **Outlier Analysis:** What's unique or contradictory?
   - **Insight Extraction:** What did we learn that's actionable?

6. **Deliverables**
   - Key findings with supporting quotes
   - Themes and patterns
   - User pain points and needs
   - Opportunities for product/design
   - Personas or user journey maps (if applicable)
   - Recommendations with evidence

**Deliverable:** User interview research report with insights and recommendations

### Workflow 2: Usability Testing

**Objective:** Evaluate product usability and identify improvement opportunities

**Steps:**
1. **Define Testing Scope**
   - What are we testing? (prototype, feature, full product)
   - What fidelity? (low-fi wireframes, high-fi prototype, live product)
   - What tasks should users complete?
   - What are success criteria?
   - What metrics will we track?

2. **Create Test Plan**
   - **Tasks:** 3-5 realistic tasks users should complete
     - Specific and scenario-based
     - Cover critical user flows
     - Vary in complexity
   - **Success Metrics:**
     - Task completion rate
     - Time on task
     - Number of errors
     - Satisfaction rating (post-task)
   - **Test Script:**
     - Welcome and context
     - Think-aloud instructions
     - Task scenarios
     - Post-task questions
     - Overall experience questions

3. **Recruit Participants**
   - Representative users (not internal team)
   - 5-8 participants typically sufficient to find major issues
   - Screen for relevant characteristics
   - Mix of experience levels if appropriate

4. **Conduct Usability Tests**
   - **Moderated Testing:**
     - Observer present (in-person or remote)
     - Ask participants to think aloud
     - Note observations, quotes, pain points
     - Probe when stuck or confused
     - Don't provide help unless necessary for progress

   - **Unmoderated Testing:**
     - Self-guided with instructions
     - Screen recording and analytics
     - Post-task surveys
     - Useful for large sample or quantitative validation

5. **Analyze Results**
   - **Task-Level Analysis:**
     - Completion rate by task
     - Time to complete
     - Common errors or friction points
     - Paths taken (expected vs. actual)

   - **Issue Identification:**
     - What went wrong and where?
     - Why did it go wrong? (root cause)
     - How severe? (critical, major, minor)
     - How frequent? (all users, most, some, one)

   - **Positive Observations:**
     - What worked well?
     - What delighted users?
     - What met or exceeded expectations?

6. **Prioritize Findings**
   - **Severity × Frequency Matrix:**
     - Critical + Frequent = P0 (fix immediately)
     - Critical + Infrequent = P1 (fix soon)
     - Major + Frequent = P1 (fix soon)
     - Major + Infrequent = P2 (fix when possible)
     - Minor = P3 (nice to fix)

   - Focus on highest impact issues

7. **Recommendations**
   - Specific, actionable fixes for each issue
   - Design alternatives to test
   - Quick wins vs. strategic redesigns
   - Validation plan for fixes

**Deliverable:** Usability test report with prioritized issues and recommendations

### Workflow 3: Persona Development

**Objective:** Create research-based user personas to guide product decisions

**Steps:**
1. **Gather User Data**
   - User interviews (10-20 across segments)
   - Survey data (quantitative validation)
   - Analytics data (behavioral patterns)
   - Customer support data (common issues)
   - Sales/CS team insights

2. **Identify Patterns**
   - Demographic patterns
   - Behavioral patterns (how they use product)
   - Goal patterns (what they're trying to achieve)
   - Pain point patterns (common frustrations)
   - Motivation patterns (why they use product)
   - Attitude patterns (tech-savvy, risk-averse, etc.)

3. **Segment Users**
   - Cluster users by meaningful differences
   - Typically 3-5 personas (more = less useful)
   - Each persona should be distinct and actionable
   - Validate segments with data

4. **Build Persona Profiles**
   - **Demographic Info:**
     - Name (fictional but memorable)
     - Age, role, location (if relevant)
     - Photo (stock photo for visualization)

   - **Background:**
     - Job/life context
     - Relevant responsibilities
     - Technical proficiency

   - **Goals & Motivations:**
     - What are they trying to achieve?
     - What drives their decisions?
     - Success criteria

   - **Pain Points & Frustrations:**
     - Current challenges
     - Blockers to success
     - Workarounds they use

   - **Behaviors & Preferences:**
     - How they work/live
     - Tools they use
     - Communication preferences
     - Decision-making style

   - **Quote:**
     - Representative quote from research

   - **"A Day in the Life":**
     - Typical workflow or day
     - When/how product fits in

5. **Validate Personas**
   - Share with team for feedback
   - Test against real user data
   - Confirm with additional research if needed
   - Refine based on feedback

6. **Socialize & Use**
   - Present to broader team
   - Create posters or reference cards
   - Reference in product discussions
   - Use in design reviews ("What would Sarah think?")
   - Update as you learn more

**Deliverable:** Persona profiles with supporting research data

### Workflow 4: Journey Mapping

**Objective:** Visualize end-to-end user experience to identify opportunities

**Steps:**
1. **Define Journey Scope**
   - Which persona?
   - Which journey? (onboarding, core workflow, purchase, etc.)
   - Start and end points
   - Key touchpoints to include

2. **Gather Journey Data**
   - User interviews about their process
   - Observational research (watch users)
   - Analytics (actual paths taken)
   - Support tickets (where things break)
   - Survey feedback

3. **Map Journey Stages**
   - Identify 5-10 key stages from start to finish
   - For each stage:
     - **User Actions:** What are they doing?
     - **Touchpoints:** What are they interacting with?
     - **Thoughts:** What are they thinking?
     - **Emotions:** How do they feel? (frustration, confidence, delight)
     - **Pain Points:** What's hard or broken?
     - **Opportunities:** How could we improve?

4. **Visualize Journey**
   - Timeline or flow from left to right
   - Stages clearly delineated
   - Emotion curve (highs and lows)
   - Pain points highlighted
   - Opportunities noted
   - Use color, icons, quotes for clarity

5. **Analyze & Prioritize**
   - Identify critical pain points
   - Find moments of truth (high-impact moments)
   - Spot opportunities for delight
   - Prioritize by impact and feasibility

6. **Generate Recommendations**
   - Quick fixes for pain points
   - Strategic improvements for moments of truth
   - Delight opportunities
   - Cross-functional actions (product, marketing, support)

**Deliverable:** User journey map with pain points, emotions, and opportunities

### Workflow 5: Research Synthesis & Insight Communication

**Objective:** Synthesize research findings and communicate insights effectively

**Steps:**
1. **Organize Raw Data**
   - Transcripts, notes, recordings
   - Survey responses
   - Analytics data
   - Observation notes

2. **Code & Tag Data**
   - Apply tags to key moments
   - Use consistent coding framework
   - Tag themes, pain points, behaviors, quotes
   - Track frequency of codes

3. **Affinity Mapping**
   - Group similar insights together
   - Create hierarchy (themes → sub-themes → specific observations)
   - Identify patterns and outliers
   - Build narrative from patterns

4. **Extract Key Insights**
   - What are the big takeaways?
   - What surprised us?
   - What confirmed hypotheses?
   - What contradicted assumptions?
   - What's actionable?

5. **Build Evidence for Each Insight**
   - Quantify when possible (X out of Y participants)
   - Include supporting quotes
   - Show behavioral data
   - Link to specific examples

6. **Craft Insight Statements**
   - **Format:** [Observation] + [Implication] + [Recommendation]
   - **Example:** "Users struggle to find the export feature (mentioned by 7/8 participants), leading them to use workarounds or give up. → Recommend making export more prominent in main navigation."
   - Clear, specific, actionable

7. **Create Presentation**
   - **Executive Summary:** Key findings and recommendations
   - **Methodology:** How we conducted research
   - **Participant Overview:** Who we talked to
   - **Key Insights:** One insight per slide with evidence
   - **Recommendations:** Prioritized actions
   - **Appendix:** Detailed data, quotes, methodology notes

8. **Communication Formats**
   - **For Executives:** High-level summary, key recommendations, business impact
   - **For Product/Design:** Detailed insights, user quotes, design implications
   - **For Engineering:** Specific issues, reproduction steps, severity
   - **For Marketing/Sales:** User language, value props, positioning insights

**Deliverable:** Research synthesis presentation tailored to audience

## Quick Reference

| Action | Command/Trigger |
|--------|-----------------|
| Plan user interviews | "Help me plan user interviews for [product/feature]" |
| Create interview guide | "Create interview guide for [research goal]" |
| Usability test plan | "Create usability test plan for [feature]" |
| Analyze interview data | "Synthesize insights from these interview notes" |
| Build personas | "Create user personas based on this research" |
| Journey map | "Create user journey map for [flow]" |

## Research Methods Overview

### When to Use Each Method

| Method | Best For | Sample Size | Timeline |
|--------|----------|-------------|----------|
| **User Interviews** | Deep understanding, exploratory, "why" | 5-10 per segment | 2-3 weeks |
| **Usability Testing** | Evaluate specific designs, find issues | 5-8 participants | 1-2 weeks |
| **Surveys** | Quantitative validation, prioritization | 100+ responses | 1-2 weeks |
| **Field Studies** | Contextual understanding, natural behavior | 5-10 sessions | 3-4 weeks |
| **Diary Studies** | Behavior over time, longitudinal | 10-20 participants | 2-4 weeks |
| **Card Sorting** | Information architecture, categorization | 15-30 participants | 1 week |
| **A/B Testing** | Validate design decisions, optimize | 1000+ per variant | 1-2 weeks |
| **Analytics Analysis** | Behavioral patterns, usage metrics | All users | Ongoing |

## Interview Question Types

### Good Open-Ended Questions
- "Tell me about the last time you..."
- "Walk me through your process for..."
- "What's most challenging about..."
- "How do you currently..."
- "What would make this easier?"
- "Why is that important to you?"

### Questions to Avoid
- Leading: "Don't you think this feature is useful?" → "How do you feel about this feature?"
- Closed: "Do you like this?" → "What do you think about this?"
- Hypothetical: "Would you use this?" → "Tell me about a time you needed this."
- Multiple: "What do you think about A and B and C?" → Ask one at a time

## Usability Testing Best Practices

### Think-Aloud Protocol
- "As you complete these tasks, please think out loud."
- "Tell me what you're looking at, thinking, and trying to do."
- "There are no wrong answers; we're testing the design, not you."

### When Participants Get Stuck
- Don't immediately help; let them struggle (reveals issues)
- Probe: "What are you thinking right now?"
- "What are you looking for?"
- "What would you expect to happen?"
- Only provide hints if completely blocked

### What to Observe
- Where they look first
- What they click/tap
- What they say (verbally and non-verbally)
- Hesitations and confusion
- Delightful moments
- Workarounds and coping strategies

## Persona Template

```markdown
# Persona: [Name]

![Photo]

**Age:** XX | **Role:** [Job Title] | **Location:** [City/Region]

## Background
[2-3 sentences about their role, experience, and context]

## Goals & Motivations
- Goal 1
- Goal 2
- Goal 3

## Pain Points & Frustrations
- Pain point 1
- Pain point 2
- Pain point 3

## Behaviors & Preferences
- **Tech Proficiency:** [Low/Medium/High]
- **Tools Used:** [List key tools]
- **Communication Style:** [Preference]
- **Decision Style:** [Data-driven, intuitive, collaborative, etc.]

## Quote
> "[Representative quote from research that captures their perspective]"

## A Day in the Life
[Narrative describing typical workflow and how product fits in]

## How [Product] Helps
- Value 1
- Value 2
- Value 3

---
**Based on:** X interviews with [segment description]
```

## Best Practices

- **Recruit real users:** Friends and family don't count
- **Small sample, deep insights:** 5-8 interviews reveal most issues
- **Record everything:** Memory is unreliable; transcripts are gold
- **Stay curious:** Even "obvious" answers deserve a "why?"
- **Avoid confirmation bias:** Actively look for disconfirming evidence
- **Show, don't just tell:** Quotes and clips are more compelling than summaries
- **Focus on behavior, not opinions:** What people do > what they say they do
- **Iterate research questions:** Refine as you learn
- **Synthesize regularly:** Don't wait until all data is collected
- **Share insights broadly:** Research is only valuable if it informs decisions

## Research Report Template

```markdown
# User Research Report: [Study Name]

**Date:** [Report Date]
**Researcher:** Claude User Research Agent
**Study Type:** [Interviews/Usability Testing/etc.]

## Executive Summary
- **Objective:** [What we set out to learn]
- **Method:** [How we conducted research]
- **Participants:** [Who we talked to]
- **Key Findings:** [Top 3-5 insights]
- **Recommendations:** [Top 3 actions]

## Research Objectives
1. Objective 1
2. Objective 2

## Methodology
- **Method:** [Interviews, usability testing, etc.]
- **Participants:** [n=X, description of who]
- **Recruitment:** [How we found them]
- **Session Details:** [Duration, format, compensation]
- **Analysis:** [How we synthesized data]

## Key Findings

### Finding 1: [Insight Title]
**Observation:** [What we observed]
**Evidence:** [Data, quotes, frequency]
**Implication:** [What this means for product]

> "[Supporting quote from participant]"
> – Participant X

[Repeat for each finding]

## Pain Points & Opportunities

### Pain Point 1
**Description:** [What's broken or frustrating]
**Impact:** [High/Medium/Low]
**Frequency:** [X/Y participants mentioned]
**Opportunity:** [How we could address]

## Recommendations

### Priority 1: [Recommendation]
**Rationale:** [Why this matters]
**Impact:** [Expected benefit]
**Effort:** [Low/Medium/High]
**Evidence:** [Supporting data]

[Repeat for each recommendation]

## Participant Overview
- [Brief description of who we talked to]
- [Demographic breakdown if relevant]

## Appendix
- Interview guide
- Detailed notes or transcripts
- Additional quotes
- Methodology details
```

## Integration with Other Skills

- **Use with `survey-analyzer`:** Combine qualitative and quantitative research
- **Use with `data-analyzer`:** Validate qualitative insights with behavioral data
- **Use with `competitive-intelligence`:** User research on competitor products
- **Use with `market-research-analyst`:** Understand user segments and needs
- **Use with `ui-builder`:** Inform design decisions with user insights

## Common Pitfalls to Avoid

- **Asking for solutions:** Users are experts in problems, not solutions
- **Small sample fallacy:** Don't generalize from 1-2 participants
- **Confirmation bias:** Only hearing what you want to hear
- **Leading questions:** Influencing responses
- **Not probing deeply:** Staying at surface level
- **Researching the wrong users:** Talking to edge cases instead of core users
- **Analysis paralysis:** Waiting for perfect certainty
- **Not sharing insights:** Research that stays in a report is wasted
- **Ignoring context:** Not understanding where/why behavior happens
- **Defensive listening:** Taking feedback personally instead of as data
